# schema: ssot.ai.odoo_ai.v1
# AI provider configuration for Odoo 19 CE deployment.
# This file governs which AI backend is active and its parameters.
# Referenced by: spec/monorepo-endstate/prd.md O5.1
#
# ── GOAL: Replace Odoo EE AI (BYOM) with CE-native IPAI bridge ────────────────
# Odoo 19 EE "Ask AI" uses Bring Your Own Model (BYOM): the enterprise AI app
# lets you configure your own OpenAI or Google Gemini API key directly in
# AI app → Configuration → Settings → Providers. IAP credits are NOT used for
# v19 AI features (IAP = OCR/document digitization only).
#
# This deployment replaces EE BYOM with the IPAI bridge pattern:
#   EE:  Odoo AI app + ai.google.api_key (system param) → Gemini directly
#   CE:  ipai_ai_widget addon + ir.config_parameter:bridge_url → IPAI → Gemini
#
# Both paths use the same Gemini API key — the key lives at Vercel (IPAI side),
# not inside Odoo. This keeps Odoo clean and provider-agnostic.
#
# ── Surfaces replaced ─────────────────────────────────────────────────────────
# EE surfaces:      top-bar Ask AI, Ctrl+K palette, html editor action,
#                   AI agents (RAG+pgvector), AI fields (Studio), voice transcription
# CE covered now:   chatter button (ipai_ai_widget) — partial replacement
# CE gap:           html editor action requires OCA port to 19.0 (see task T-1)
#
# mode values:
#   gemini  — IPAI AI Provider Bridge (default, SaaS-grade, Vercel-hosted)
#   ollama  — OCA ai_oca_native_generate_ollama (self-hosted, offline/local tenants)
#
# To enable Ollama fallback: set mode: ollama and provide ollama_endpoint below.
# To revert to Gemini primary: set mode: gemini (or remove the file entirely).
#
# IMPORTANT: mode=ollama requires ai_oca_native_generate_ollama installed in Odoo.
# Never set mode=odoo_iap — IAP requires EE license (CE-only constraint).

version: "1.0.0"
schema: ssot.ai.odoo_ai.v1
last_reviewed: "2026-02-27"

# ── Primary AI mode ──────────────────────────────────────────────────────────
mode: gemini   # gemini | ollama

# ── Gemini (primary, default) ─────────────────────────────────────────────────
gemini:
  bridge: ipai_ai_tools_bridge
  # URL is read from ir.config_parameter:ipai_ai_widget.bridge_url in Odoo.
  # Value must be set via Odoo Settings → Technical → Parameters, NOT committed here.
  endpoint_param: ipai_ai_widget.bridge_url
  model: gemini-2.0-flash-preview
  # Secret: gemini_api_key (see ssot/secrets/registry.yaml)
  # Key lives at: Vercel env var GEMINI_API_KEY (ops-console project)
  required_secret: gemini_api_key
  failure_code: AI_KEY_NOT_CONFIGURED    # HTTP 503 when key is missing
  response_shape:
    - provider
    - text
    - model
    - trace_id

# ── Ollama (opt-in fallback for offline / local tenants) ─────────────────────
ollama:
  oca_module: ai_oca_native_generate_ollama
  # Endpoint is configured inside Odoo (OCA module settings).
  # Typical value: http://localhost:11434 (or remote Ollama host)
  default_endpoint: http://localhost:11434
  default_model: llama3
  notes: >
    Opt-in only. Set mode: ollama to enable. Requires ai_oca_native_generate_ollama
    installed and active in Odoo. Module available at OCA/ai (port to 19.0 needed).
    Fallback disables telemetry (no trace_id) — acceptable for offline tenants only.

# ── Odoo AI surfaces covered by this config ───────────────────────────────────
surfaces:
  - name: chatter_button
    addon: ipai_ai_widget
    description: "OWL 2 Ask AI button in mail.chatter (CE path for html editor assistant)"
    modes: [gemini, ollama]
  - name: html_editor_action
    description: >
      Native Odoo 19 html editor AI action (EE/BYOM — OpenAI or Gemini key in AI app Settings).
      Appears in: Knowledge, Discuss, email compose, notes.
      CE gap: requires OCA ai_oca_native_generate_ollama ported to 19.0 and reconfigured
      to call IPAI bridge instead of Ollama (task T-1 in spec/ai-bridge/tasks.md).
    modes: []           # no CE path yet; gap noted in ssot/parity/ee_to_oca_matrix.yaml
  - name: top_bar_ask_ai
    description: >
      EE top-bar Ask AI button (Ctrl+K palette). Full RAG agent with pgvector.
      No CE equivalent — requires AI agents framework (enterprise_ai module).
    modes: []           # no CE path; accepted gap

# ── Anthropic / Claude provider ───────────────────────────────────────────────
# Added per spec/ipai-llm-supabase-bridge/prd.md O2 + O5.3.
# Claude is IPAI's first-class AI provider — not available in Odoo EE natively.
# Enabled once vendor/apexive-llm llm_anthropic port to 19.0 is complete (see
# ssot/ai/dependencies.yaml: apexive_odoo_llm status).
anthropic:
  bridge: vendor_apexive_llm_anthropic     # llm_anthropic module in vendor tree
  module: llm_anthropic                    # addons path: vendor/apexive-llm/llm_anthropic
  models:
    - claude-sonnet-4-6
    - claude-haiku-4-5-20251001
    - claude-opus-4-6
  required_secret: anthropic_api_key       # registered in ssot/secrets/registry.yaml
  endpoint_param: anthropic.api_key        # ir.config_parameter key set in Odoo Settings
  failure_code: AI_KEY_NOT_CONFIGURED      # HTTP 503 when key is missing (consistent with gemini)
  status: pending_port                     # allowed: pending_port | active | deprecated
  differentiator: >
    Anthropic Claude is not supported in Odoo 19 Enterprise (EE ships ChatGPT + Gemini BYOK only).
    IPAI's llm_anthropic port gives tenants Claude support that Enterprise does not provide.

# ── CE vs EE vs IPAI capability stance ───────────────────────────────────────
# Codified from Odoo 19 release notes audit (2026-02-28).
ce_ee_ipai_gap:
  community_edition:
    ai_native: false
    notes: "Zero native AI in CE. All 17 Odoo 19 AI features are Enterprise-only."
  enterprise:
    ai_native: true
    providers_supported: [openai, gemini]
    providers_missing: [anthropic]
    notes: >
      Odoo 19 EE ships ChatGPT 5.0 and Gemini BYOK (via AI app → Configuration → Providers).
      No Anthropic/Claude support. IAP credits apply to OCR/document digitization only, not AI chat.
  ipai:
    ai_native: false                       # CE base, no native AI
    providers_supported: [gemini, anthropic, ollama]
    differentiators:
      - "Claude support (llm_anthropic) — not available in EE"
      - "Supabase observability bridge (ipai_llm_supabase_bridge) — real-time LLM telemetry"
      - "Provider-agnostic bridge — swap backends without Odoo config changes"

# ── Provider policy (SSOT enforced) ──────────────────────────────────────────
provider_policy:
  registration_required: true
  identity_sor: supabase        # mirrors ssot/runtime/prod_settings.yaml auth.identity_sor
  invitation_issuer: supabase   # Supabase mints invite tokens; Odoo may send branded email
  notes: >
    All AI providers must be registered in this file before use. Using an unregistered
    provider is a policy violation and will be caught by check_ai_dependencies.py.
    Identity SoR is Supabase; Odoo is a relying party (Rule 9, ssot-platform.md).
  fail_closed_semantics:
    missing_key_code: AI_KEY_NOT_CONFIGURED
    http_status: 503
    remediation_ref: ssot/secrets/registry.yaml
  first_class_providers:
    - id: anthropic
      priority: 1
      reason: "IPAI canonical provider; Claude 4.x model family; IPAI differentiator vs EE"
    - id: gemini
      priority: 2
      reason: "Default active provider; production-ready Gemini 2.0 Flash bridge"
  optional_providers:
    - id: ollama
      reason: "Opt-in for offline/air-gapped tenants; no telemetry"
  prohibited_providers:
    - id: odoo_iap
      reason: "Enterprise license required; CE-only constraint (CLAUDE.md §Critical Rules)"
    - id: openai_direct
      reason: >
        Not prohibited but not first-class. Use anthropic or gemini for IPAI tenants.
        Only valid for compatibility testing against llm_openai module.

# ── External dependency references ────────────────────────────────────────────
# IDs must exactly match ssot/ai/dependencies.yaml dependency.id values.
# Gate: a provider whose upstream dependency has lifecycle=unknown or pinned_ref=null
#       MUST NOT be activated in production Odoo.
dependencies:
  - apexive_odoo_llm    # required for: anthropic provider, llm surfaces, supabase bridge
  - oca_ai_ollama       # required for: ollama provider, html_editor_action surface (opt-in)

# Structured gate policy — mirrors invariants in ssot/ai/dependencies.yaml.
# Evaluated by check_ai_dependencies.py; must stay in sync with invariants block.
dependency_policy:
  prod_activation_requires:
    - "status.lifecycle in ['planned', 'active']"
    - "upstream.pinned_ref != null"
  treat_unknown_as: "blocked"

# ── Prohibited modes ─────────────────────────────────────────────────────────
prohibited:
  - mode: odoo_iap
    reason: "Requires Odoo Enterprise license. CE-only constraint (CLAUDE.md §Critical Rules)."
