#!/usr/bin/env bash
# Memory Pack Distillation Script
# Fetches summaries from Supabase and updates LLM packs
set -euo pipefail

# Required environment variables
: "${SUPABASE_URL:?SUPABASE_URL is required}"
: "${SUPABASE_SERVICE_ROLE_KEY:?SUPABASE_SERVICE_ROLE_KEY is required}"

# Optional configuration
TARGET_REPO_ROOT="${TARGET_REPO_ROOT:-$(pwd)}"
OUT_DIR="$TARGET_REPO_ROOT/memory/packs"
TMP_DIR="$(mktemp -d)"
TIMESTAMP="$(date -u +%Y-%m-%dT%H:%M:%SZ)"

cleanup() {
    rm -rf "$TMP_DIR"
}
trap cleanup EXIT

echo "=== Memory Pack Distillation ==="
echo "Timestamp: $TIMESTAMP"
echo "Output directory: $OUT_DIR"
echo ""

# ----------------------------------------------------------------------------
# Fetch summaries from Supabase
# ----------------------------------------------------------------------------

echo "Fetching job summaries..."
curl -sS "$SUPABASE_URL/rest/v1/rpc/get_ops_summary" \
    -H "apikey: $SUPABASE_SERVICE_ROLE_KEY" \
    -H "Authorization: Bearer $SUPABASE_SERVICE_ROLE_KEY" \
    -H "Content-Type: application/json" \
    -d '{}' \
    > "$TMP_DIR/ops_summary.json" 2>/dev/null || echo '{"jobs_24h":0,"success_rate":0,"active_integrations":0}' > "$TMP_DIR/ops_summary.json"

echo "Fetching integration health..."
curl -sS "$SUPABASE_URL/rest/v1/v_integration_health?select=slug,name,status,health_status,pending_events,failed_events_24h" \
    -H "apikey: $SUPABASE_SERVICE_ROLE_KEY" \
    -H "Authorization: Bearer $SUPABASE_SERVICE_ROLE_KEY" \
    > "$TMP_DIR/integrations.json" 2>/dev/null || echo '[]' > "$TMP_DIR/integrations.json"

echo "Fetching recent syncs..."
curl -sS "$SUPABASE_URL/rest/v1/v_recent_syncs?select=source_provider,destination_provider,status,artifact_name,created_at&limit=10" \
    -H "apikey: $SUPABASE_SERVICE_ROLE_KEY" \
    -H "Authorization: Bearer $SUPABASE_SERVICE_ROLE_KEY" \
    > "$TMP_DIR/recent_syncs.json" 2>/dev/null || echo '[]' > "$TMP_DIR/recent_syncs.json"

# ----------------------------------------------------------------------------
# Generate recent changes for common pack
# ----------------------------------------------------------------------------

echo "Generating common pack updates..."
cat > "$OUT_DIR/common/90_recent_changes.md" <<EOF
# Recent Changes

*Last updated: $TIMESTAMP*

## System Health

\`\`\`json
$(cat "$TMP_DIR/ops_summary.json" | head -c 500)
\`\`\`

## Integration Status

$(cat "$TMP_DIR/integrations.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    if not data:
        print('No integrations configured.')
    else:
        print('| Integration | Status | Health | Pending |')
        print('|-------------|--------|--------|---------|')
        for i in data[:10]:
            print(f\"| {i.get('name', 'N/A')} | {i.get('status', 'N/A')} | {i.get('health_status', 'N/A')} | {i.get('pending_events', 0)} |\")
except:
    print('Unable to parse integration data.')
" 2>/dev/null || echo "Unable to fetch integration status.")

## Recent Artifact Syncs

$(cat "$TMP_DIR/recent_syncs.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    if not data:
        print('No recent syncs.')
    else:
        print('| Artifact | Source | Dest | Status |')
        print('|----------|--------|------|--------|')
        for s in data[:10]:
            print(f\"| {s.get('artifact_name', 'N/A')[:30]} | {s.get('source_provider', 'N/A')} | {s.get('destination_provider', 'N/A')} | {s.get('status', 'N/A')} |\")
except:
    print('Unable to parse sync data.')
" 2>/dev/null || echo "Unable to fetch sync status.")

## Notes

- This file is auto-generated by the distillation pipeline
- Manual edits will be overwritten
- See \`memory_policy.yaml\` for data sources
EOF

# ----------------------------------------------------------------------------
# Generate ChatGPT-specific recent changes (more terse)
# ----------------------------------------------------------------------------

echo "Generating ChatGPT pack updates..."
cat > "$OUT_DIR/chatgpt/90_recent_changes.md" <<EOF
# Recent Changes (ChatGPT)

*Updated: $TIMESTAMP*

## Quick Status

$(cat "$TMP_DIR/ops_summary.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    print(f\"- Jobs (24h): {data.get('jobs_24h', 'N/A')}\")
    print(f\"- Success rate: {data.get('success_rate', 'N/A')}%\")
    print(f\"- Active integrations: {data.get('active_integrations', 'N/A')}\")
except:
    print('- Status: Unable to fetch')
" 2>/dev/null || echo "- Status: Unavailable")

## Active Issues

- Check \`gh issue list -R Insightpulseai-net/odoo-ce --state open\`

## Commands

\`\`\`bash
# Check health
./scripts/repo_health.sh

# Check syncs
SELECT status, COUNT(*) FROM marketplace.artifact_syncs GROUP BY status;
\`\`\`
EOF

# ----------------------------------------------------------------------------
# Generate Claude-specific recent changes (more detailed)
# ----------------------------------------------------------------------------

echo "Generating Claude pack updates..."
cat > "$OUT_DIR/claude/90_recent_changes.md" <<EOF
# Recent Changes (Claude)

*Last updated: $TIMESTAMP*
*Distilled from: Supabase ops schema, marketplace schema*

## Operational Summary

$(cat "$TMP_DIR/ops_summary.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    print('### Job Execution (Last 24 Hours)')
    print(f\"- Total jobs executed: {data.get('jobs_24h', 'N/A')}\")
    print(f\"- Success rate: {data.get('success_rate', 'N/A')}%\")
    print(f\"- Active integrations: {data.get('active_integrations', 'N/A')}\")
    if data.get('success_rate', 100) < 90:
        print('')
        print('**Warning**: Success rate below 90%. Check failed jobs.')
except:
    print('Unable to fetch operational summary.')
" 2>/dev/null || echo "Operational data unavailable.")

## Integration Health

$(cat "$TMP_DIR/integrations.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    if not data:
        print('No integrations configured.')
    else:
        healthy = [i for i in data if i.get('health_status') == 'healthy']
        unhealthy = [i for i in data if i.get('health_status') != 'healthy']
        print(f'### Healthy ({len(healthy)})')
        for i in healthy[:5]:
            print(f\"- {i.get('name')}\")
        if unhealthy:
            print(f'')
            print(f'### Needs Attention ({len(unhealthy)})')
            for i in unhealthy:
                print(f\"- **{i.get('name')}**: {i.get('health_status')} (pending: {i.get('pending_events', 0)}, failed: {i.get('failed_events_24h', 0)})\")
except:
    print('Unable to parse integration data.')
" 2>/dev/null || echo "Integration data unavailable.")

## Recent Artifact Syncs

$(cat "$TMP_DIR/recent_syncs.json" | python3 -c "
import json, sys
try:
    data = json.load(sys.stdin)
    if not data:
        print('No recent syncs recorded.')
    else:
        completed = len([s for s in data if s.get('status') == 'completed'])
        failed = len([s for s in data if s.get('status') == 'failed'])
        print(f'Summary: {completed} completed, {failed} failed (last 10 syncs)')
        print('')
        print('| Artifact | Flow | Status | Time |')
        print('|----------|------|--------|------|')
        for s in data[:10]:
            name = s.get('artifact_name', 'N/A')[:25]
            flow = f\"{s.get('source_provider', '?')} -> {s.get('destination_provider', '?')}\"
            status = s.get('status', 'N/A')
            time = s.get('created_at', 'N/A')[:16]
            print(f'| {name} | {flow} | {status} | {time} |')
except:
    print('Unable to parse sync data.')
" 2>/dev/null || echo "Sync data unavailable.")

## Recommended Actions

Based on current state:

1. **If failed syncs exist**: Check \`marketplace.artifact_syncs\` for error messages
2. **If integrations unhealthy**: Verify OAuth tokens and webhook endpoints
3. **If success rate low**: Review \`ops.job_events\` for error patterns

## Debug Queries

\`\`\`sql
-- Check failed syncs
SELECT id, artifact_name, error_message, created_at
FROM marketplace.artifact_syncs
WHERE status = 'failed'
ORDER BY created_at DESC
LIMIT 5;

-- Check pending webhooks
SELECT source, event_type, COUNT(*)
FROM marketplace.webhook_events
WHERE NOT processed
GROUP BY source, event_type;

-- Check job failures
SELECT job_type, COUNT(*), MAX(created_at) as last_failure
FROM ops.job_runs
WHERE status = 'failed'
AND created_at > NOW() - INTERVAL '24 hours'
GROUP BY job_type;
\`\`\`

---
*This file is auto-generated. See \`scripts/memory/distill_packs.sh\`*
EOF

# ----------------------------------------------------------------------------
# Summary
# ----------------------------------------------------------------------------

echo ""
echo "=== Distillation Complete ==="
echo "Files updated:"
find "$OUT_DIR" -name "90_*.md" -exec ls -la {} \;
echo ""
echo "Token estimates (approximate):"
for pack in common chatgpt claude; do
    total=0
    for f in "$OUT_DIR/$pack"/*.md; do
        if [ -f "$f" ]; then
            words=$(wc -w < "$f")
            total=$((total + words))
        fi
    done
    tokens=$((total * 4 / 3))  # Rough estimate: 1 token ~ 0.75 words
    echo "  $pack: ~$tokens tokens"
done
