# Skill: Supabase Schema Catalog

## Summary

This skill maintains an **offline JSON catalog** of a Supabase Postgres schema so that agents can:
- Understand tables, columns, and types without querying the live database.
- Generate SQL, documentation, and migrations using the cached schema.
- Avoid hitting Supabase for every schema-related question.

The catalog is generated by running a single SQL query against the Supabase database and writing the result to `catalog/schema_catalog.json` in this skill directory.

---

## Inputs

- Environment variable `SUPABASE_DB_URL`:
  - A Postgres connection string for your Supabase database.
  - Preferably a **read-only** or low-privilege role.

Optionally:
- `SCHEMA_FILTER` (comma-separated schemas), default: all non-system schemas.

---

## Outputs

- `catalog/schema_catalog.json` – pretty-printed JSON array of objects:

```jsonc
[
  {
    "schema": "public",
    "table": "my_table",
    "columns": [
      {
        "name": "id",
        "data_type": "uuid",
        "is_nullable": "NO",
        "column_default": "gen_random_uuid()"
      },
      {
        "name": "created_at",
        "data_type": "timestamp with time zone",
        "is_nullable": "YES",
        "column_default": "now()"
      }
      // ...
    ]
  }
  // ...
]
```

Agents can:

* Scan this file to understand schema.
* Build table/column maps.
* Cross-reference with Superset/Odoo mappings.

---

## How It Works

1. `scripts/build_schema_catalog.sql`:

   * A single SQL query that:

     * Reads from `information_schema.tables` and `information_schema.columns`.
     * Excludes system schemas (`pg_catalog`, `information_schema`).
     * Optionally filters by `SCHEMA_FILTER`.
     * Aggregates into a JSON structure.

2. `scripts/build_schema_catalog.sh`:

   * Small wrapper around `psql`:

     * Ensures `SUPABASE_DB_URL` is set.
     * Executes the SQL file.
     * Writes the resulting JSON into `catalog/schema_catalog.json`.

3. Agents:

   * Treat `catalog/schema_catalog.json` as the **canonical schema** for the Supabase project.
   * Only request a refresh when the schema actually changes (migration, new module, etc.).

---

## Usage

### 1. Configure Environment

Set `SUPABASE_DB_URL` in your CI / dev environment:

```bash
export SUPABASE_DB_URL='postgres://USER:PASSWORD@HOST:PORT/DATABASE?sslmode=require'
```

Optional: restrict to specific schemas (comma-separated):

```bash
export SCHEMA_FILTER='public,realm,scout'
```

### 2. Generate the Catalog

Run:

```bash
cd skills/user/supabase-schema-catalog
./scripts/build_schema_catalog.sh
```

This will:

* Connect to the Supabase DB.
* Run the SQL in `scripts/build_schema_catalog.sql`.
* Write pretty JSON to `catalog/schema_catalog.json`.

### 3. Consume in Agents

Agents running in this environment should:

* Treat `catalog/schema_catalog.json` as read-only schema knowledge.
* Use it to:

  * Answer schema questions,
  * Generate SQL,
  * Map Supabase tables to Odoo/Superset/n8n entities,
  * Build schema-aware documentation.

If schema changes:

* Re-run `./scripts/build_schema_catalog.sh` to refresh the file.
* Commit updated `schema_catalog.json` into Git if you want it versioned.

---

## Integration with InsightPulse Stack

### Superset Integration

* Use catalog to auto-generate Superset dataset definitions
* Map Supabase tables to virtual datasets
* Generate SQLAlchemy URI configs

### Odoo Bridge

* Map Supabase tables to external Odoo models
* Generate `ipai_*` module stubs for Supabase-backed models
* Cross-reference authentication (Supabase Auth ↔ Odoo users)

### n8n Workflows

* Schema-aware data transformations
* Auto-generate Supabase node configurations
* Validate data shapes before insert/update

---

## Safety & Constraints

* The skill **never** exposes credentials in the catalog file.
* Use a **read-only** DB user for `SUPABASE_DB_URL` wherever possible.
* This catalog is a **snapshot**; it will drift if the schema changes and you don't regenerate it.
* Do not store secrets or PII in the catalog; it only contains structural metadata (schemas/tables/columns).

---

## CI/CD Integration

Add to your GitHub Actions workflow:

```yaml
- name: Refresh Supabase Schema Catalog
  env:
    SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
    SCHEMA_FILTER: public,auth,storage
  run: |
    cd skills/user/supabase-schema-catalog
    ./scripts/build_schema_catalog.sh

- name: Commit updated catalog
  run: |
    git config user.name "github-actions"
    git config user.email "actions@github.com"
    git add skills/user/supabase-schema-catalog/catalog/schema_catalog.json
    git diff --staged --quiet || git commit -m "chore: refresh supabase schema catalog"
```

---

## Troubleshooting

| Issue                        | Solution                                          |
| ---------------------------- | ------------------------------------------------- |
| `SUPABASE_DB_URL is not set` | Export the connection string before running       |
| Empty JSON output            | Check `SCHEMA_FILTER` isn't excluding all schemas |
| Connection timeout           | Verify network access and SSL settings            |
| Permission denied            | Ensure DB user has SELECT on `information_schema` |

---

## Version History

* **1.0.0** (2025-01): Initial skill implementation
  * SQL-based schema extraction
  * Shell wrapper with filtering support
  * Pretty-printed JSON output
