name: Lakehouse Smoke Test

on:
  pull_request:
    paths:
      - 'infra/lakehouse/**'
      - 'tools/catalog/**'
      - 'backend/**'
  push:
    branches: [main, master]
    paths:
      - 'infra/lakehouse/**'

jobs:
  smoke:
    name: Smoke Test OSS Lakehouse
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Create .env
        run: |
          cat > infra/lakehouse/.env << 'EOF'
          POSTGRES_USER=postgres
          POSTGRES_PASSWORD=testpassword123
          POSTGRES_DB=lakehouse
          MINIO_ROOT_USER=minioadmin
          MINIO_ROOT_PASSWORD=minioadmin123
          N8N_USER=admin
          N8N_PASSWORD=admin123
          EOF

      - name: Start core services
        working-directory: infra/lakehouse
        run: |
          # Start only essential services for smoke test
          docker compose up -d postgres minio

          # Wait for postgres
          echo "Waiting for PostgreSQL..."
          timeout 60 bash -c 'until docker exec lakehouse-postgres pg_isready -U postgres; do sleep 2; done'

          # Wait for MinIO
          echo "Waiting for MinIO..."
          timeout 60 bash -c 'until curl -fsS http://localhost:9000/minio/health/live; do sleep 2; done'

      - name: Start compute services
        working-directory: infra/lakehouse
        run: |
          docker compose up -d spark-master n8n

          # Wait for Spark
          echo "Waiting for Spark Master..."
          timeout 120 bash -c 'until curl -fsS http://localhost:8080 > /dev/null 2>&1; do sleep 2; done'

          # Wait for n8n
          echo "Waiting for n8n..."
          timeout 120 bash -c 'until curl -fsS http://localhost:5678/healthz > /dev/null 2>&1; do sleep 2; done'

      - name: Verify services
        run: |
          echo "=== Service Health Checks ==="

          echo "PostgreSQL:"
          docker exec lakehouse-postgres psql -U postgres -c "SELECT version();"

          echo "MinIO:"
          curl -fsS http://localhost:9000/minio/health/live && echo " OK"

          echo "Spark Master:"
          curl -fsS http://localhost:8080 > /dev/null && echo " OK"

          echo "n8n:"
          curl -fsS http://localhost:5678/healthz && echo ""

      - name: Test catalog script
        run: |
          # Install dependencies
          pip install requests

          # Test the catalog script (dry run, no actual API calls in CI)
          python -c "
          import sys
          sys.path.insert(0, 'tools/catalog')
          from databricks_org_catalog import stable_hash, catalog_org
          # Just test the hash function
          assert stable_hash('test') == stable_hash('test')
          print('Catalog script OK')
          "

      - name: Show logs on failure
        if: failure()
        working-directory: infra/lakehouse
        run: |
          echo "=== Docker Compose Logs ==="
          docker compose logs --tail=100

      - name: Cleanup
        if: always()
        working-directory: infra/lakehouse
        run: |
          docker compose down -v --remove-orphans
